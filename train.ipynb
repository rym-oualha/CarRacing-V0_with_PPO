{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CarRacing - PPO with clipped objective"
      ],
      "metadata": {
        "id": "Sr9YQy7TUWJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install video rendering dependancies"
      ],
      "metadata": {
        "id": "aVIlj5kTyWT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get update  > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg  > /dev/null 2>&1"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2022-01-05T20:20:28.599791Z",
          "iopub.execute_input": "2022-01-05T20:20:28.60023Z",
          "iopub.status.idle": "2022-01-05T20:21:10.799692Z",
          "shell.execute_reply.started": "2022-01-05T20:20:28.600191Z",
          "shell.execute_reply": "2022-01-05T20:21:10.798483Z"
        },
        "trusted": true,
        "id": "KZ4t0pstyWT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing librairies"
      ],
      "metadata": {
        "id": "buZakqYIN0rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #for error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from Agent import Agent\n",
        "from Network import Net"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:22:10.539287Z",
          "iopub.execute_input": "2022-01-05T20:22:10.53981Z",
          "iopub.status.idle": "2022-01-05T20:22:16.419405Z",
          "shell.execute_reply.started": "2022-01-05T20:22:10.539773Z",
          "shell.execute_reply": "2022-01-05T20:22:16.418261Z"
        },
        "trusted": true,
        "id": "GxKN1vBXyWT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:22:20.173885Z",
          "iopub.execute_input": "2022-01-05T20:22:20.174333Z",
          "iopub.status.idle": "2022-01-05T20:22:20.521034Z",
          "shell.execute_reply.started": "2022-01-05T20:22:20.174296Z",
          "shell.execute_reply": "2022-01-05T20:22:20.519856Z"
        },
        "trusted": true,
        "id": "PRTMgVd_yWT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Beta\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "import time\n",
        "from collections import deque"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:26:39.973344Z",
          "iopub.execute_input": "2022-01-05T20:26:39.973725Z",
          "iopub.status.idle": "2022-01-05T20:26:40.843477Z",
          "shell.execute_reply.started": "2022-01-05T20:26:39.973692Z",
          "shell.execute_reply": "2022-01-05T20:26:40.842509Z"
        },
        "trusted": true,
        "id": "0qE2Se_pyWT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install CarRacing environment in Box2D\n",
        "!pip install Box2D"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:23:38.133264Z",
          "iopub.execute_input": "2022-01-05T20:23:38.133851Z",
          "iopub.status.idle": "2022-01-05T20:23:46.87186Z",
          "shell.execute_reply.started": "2022-01-05T20:23:38.133814Z",
          "shell.execute_reply": "2022-01-05T20:23:46.87087Z"
        },
        "trusted": true,
        "id": "FLMhwjWTyWT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Video Display Functions"
      ],
      "metadata": {
        "id": "gpTS9pFOyWT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to enable rendring through video\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:22:24.160136Z",
          "iopub.execute_input": "2022-01-05T20:22:24.160685Z",
          "iopub.status.idle": "2022-01-05T20:22:24.170172Z",
          "shell.execute_reply.started": "2022-01-05T20:22:24.160649Z",
          "shell.execute_reply": "2022-01-05T20:22:24.168907Z"
        },
        "trusted": true,
        "id": "P-p4Nh9yyWT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating and testing the env"
      ],
      "metadata": {
        "id": "rswtSai0O794"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = wrap_env(gym.make(\"CarRacing-v0\"))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:23:52.065427Z",
          "iopub.execute_input": "2022-01-05T20:23:52.065802Z",
          "iopub.status.idle": "2022-01-05T20:23:52.111318Z",
          "shell.execute_reply.started": "2022-01-05T20:23:52.065769Z",
          "shell.execute_reply": "2022-01-05T20:23:52.110252Z"
        },
        "trusted": true,
        "id": "I2FEJpwRyWT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing if the Environment and Videos are working correctly\n",
        "observation = env.reset()\n",
        "while True:\n",
        "    env.render()\n",
        "    action = env.action_space.sample() \n",
        "    observation, reward, done, info = env.step(action)         \n",
        "    if done: \n",
        "      break;\n",
        "env.close()\n",
        "show_video()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:23:54.914877Z",
          "iopub.execute_input": "2022-01-05T20:23:54.915279Z",
          "iopub.status.idle": "2022-01-05T20:25:05.14294Z",
          "shell.execute_reply.started": "2022-01-05T20:23:54.915244Z",
          "shell.execute_reply": "2022-01-05T20:25:05.141775Z"
        },
        "trusted": true,
        "id": "SQh8KR4HyWT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing Training Environment"
      ],
      "metadata": {
        "id": "4XP4UoSiyWUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_stack=4\n",
        "\n",
        "transition = np.dtype([('s', np.float64, (img_stack, 96, 96)), \n",
        "                       ('a', np.float64, (3,)), ('a_logp', np.float64),\n",
        "                       ('r', np.float64), ('s_', np.float64, (img_stack, 96, 96))])\n",
        "# hyper-params\n",
        "GAMMA=0.99\n",
        "EPOCH= 8 \n",
        "MAX_SIZE = 2000 \n",
        "BATCH=128 \n",
        "EPS=0.1\n",
        "LEARNING_RATE = 0.001 "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:26:55.231204Z",
          "iopub.execute_input": "2022-01-05T20:26:55.23162Z",
          "iopub.status.idle": "2022-01-05T20:26:55.26485Z",
          "shell.execute_reply.started": "2022-01-05T20:26:55.231582Z",
          "shell.execute_reply": "2022-01-05T20:26:55.263736Z"
        },
        "trusted": true,
        "id": "upFY6iqvyWUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Training Environment\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device: ', device)\n",
        "\n",
        "seed = 0 \n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "action_repeat = 10\n",
        "env = gym.make('CarRacing-v0', verbose=0)\n",
        "state = env.reset()\n",
        "print('env.action_space.shape: ', env.action_space.shape)\n",
        "reward_threshold = env.spec.reward_threshold\n",
        "print('reward_threshold', reward_threshold)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:27:10.251809Z",
          "iopub.execute_input": "2022-01-05T20:27:10.252208Z",
          "iopub.status.idle": "2022-01-05T20:27:10.455477Z",
          "shell.execute_reply.started": "2022-01-05T20:27:10.252175Z",
          "shell.execute_reply": "2022-01-05T20:27:10.454316Z"
        },
        "trusted": true,
        "id": "M0bxUCYjyWUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing CarRacing Screenshots"
      ],
      "metadata": {
        "id": "XBQtF2fQyWUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show what a preprocessed image looks like\n",
        "frame, _, _, _ = env.step(np.array([2., 1., 1.]))\n",
        "\n",
        "print('frame.shape: ', frame.shape)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(frame)\n",
        "plt.title('original image')\n",
        "\n",
        "#-------------------------------#\n",
        "\n",
        "def rgb2gray(rgb, norm=True):\n",
        "        # rgb image -> gray [0, 1]\n",
        "    gray = np.dot(rgb[..., :], [0.299, 0.587, 0.114])\n",
        "    if norm:\n",
        "        # normalize\n",
        "        gray = gray / 128. - 1.\n",
        "    return gray\n",
        "\n",
        "img_gray = rgb2gray(frame)\n",
        "\n",
        "#-------------------------------# \n",
        "plt.subplot(1,2,2)\n",
        "plt.title('preprocessed image')\n",
        "\n",
        "print('img.shape: ', img_gray.shape)\n",
        "\n",
        "# 96 x 96 black and white image\n",
        "plt.imshow(img_gray, cmap='Greys')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:27:26.466803Z",
          "iopub.execute_input": "2022-01-05T20:27:26.467243Z",
          "iopub.status.idle": "2022-01-05T20:27:26.806249Z",
          "shell.execute_reply.started": "2022-01-05T20:27:26.467208Z",
          "shell.execute_reply": "2022-01-05T20:27:26.805269Z"
        },
        "trusted": true,
        "id": "DGJ_V2jMyWUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining some useful functions"
      ],
      "metadata": {
        "id": "LHywWkuNyWUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Wrapper():\n",
        "    \"\"\"\n",
        "    Environment wrapper for CarRacing \n",
        "    A wrapper function is a subroutine in a software library or a computer program whose main purpose is to call a second subroutine or a system call with little or no additional computation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env):\n",
        "        self.env = env  \n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.av_r = self.reward_memory()\n",
        "\n",
        "        self.die = False\n",
        "        img_rgb = env.reset()\n",
        "        img_gray = rgb2gray(img_rgb)\n",
        "        self.stack = [img_gray] * img_stack  # four frames for decision\n",
        "        return np.array(self.stack)\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0\n",
        "        for i in range(action_repeat):\n",
        "            img_rgb, reward, die, _ = env.step(action)\n",
        "            # don't penalize \"die state\"\n",
        "            if die:\n",
        "                reward += 100\n",
        "            # green penalty\n",
        "            if np.mean(img_rgb[:, :, 1]) > 185.0:\n",
        "                reward -= 0.05\n",
        "            total_reward += reward\n",
        "            # if no reward recently, end the episode\n",
        "            done = True if self.av_r(reward) <= -0.1 else False\n",
        "            if done or die:\n",
        "                break\n",
        "        img_gray = rgb2gray(img_rgb)\n",
        "        self.stack.pop(0)\n",
        "        self.stack.append(img_gray)\n",
        "        assert len(self.stack) == img_stack\n",
        "        return np.array(self.stack), total_reward, done, die\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def reward_memory():\n",
        "        # record reward for last 100 steps\n",
        "        count = 0\n",
        "        length = 100\n",
        "        history = np.zeros(length)\n",
        "\n",
        "        def memory(reward):\n",
        "            nonlocal count\n",
        "            history[count] = reward\n",
        "            count = (count + 1) % length\n",
        "            return np.mean(history)\n",
        "\n",
        "        return memory"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:27:32.46137Z",
          "iopub.execute_input": "2022-01-05T20:27:32.46175Z",
          "iopub.status.idle": "2022-01-05T20:27:32.479005Z",
          "shell.execute_reply.started": "2022-01-05T20:27:32.461717Z",
          "shell.execute_reply": "2022-01-05T20:27:32.477301Z"
        },
        "trusted": true,
        "id": "7cTcZzY_yWUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving checkpoints\n",
        "def save(agent, directory, filename, suffix):\n",
        "    torch.save(agent.net.state_dict(), '%s/%s_%s.pth' % (directory, filename, suffix))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:27:35.85337Z",
          "iopub.execute_input": "2022-01-05T20:27:35.85375Z",
          "iopub.status.idle": "2022-01-05T20:27:35.859066Z",
          "shell.execute_reply.started": "2022-01-05T20:27:35.85372Z",
          "shell.execute_reply": "2022-01-05T20:27:35.85815Z"
        },
        "trusted": true,
        "id": "7JzAC95ayWUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def the main function that train the agent \n",
        "def ppo_train(n_episodes=500, save_every=100):\n",
        "    \n",
        "    scores_deque = deque(maxlen=100)\n",
        "    scores_array = []\n",
        "    avg_scores_array = []    \n",
        "\n",
        "    timestep_after_last_save = 0\n",
        "    \n",
        "    time_start = time.time()\n",
        "\n",
        "    running_score = 0\n",
        "    state = env_wrap.reset()\n",
        "    \n",
        "    i_lim = 0\n",
        "    \n",
        "    for i_episode in range(n_episodes):\n",
        "        \n",
        "        timestep = 0\n",
        "        total_reward = 0\n",
        "        \n",
        "        ## score = 0\n",
        "        state = env_wrap.reset()\n",
        "\n",
        "        while True:    \n",
        "            \n",
        "            action, a_logp = agent.select_action(state)\n",
        "            next_state, reward, done, die = env_wrap.step( \n",
        "                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "            if agent.store((state, action, a_logp, reward, next_state)):\n",
        "                print('updating')\n",
        "                agent.update()\n",
        "            \n",
        "            total_reward += reward\n",
        "            state = next_state\n",
        "            \n",
        "            timestep += 1  \n",
        "            timestep_after_last_save += 1\n",
        "            \n",
        "            if done or die:\n",
        "                break\n",
        "                \n",
        "        running_score = running_score * 0.99 + total_reward * 0.01\n",
        "\n",
        "        scores_deque.append(total_reward)\n",
        "        scores_array.append(total_reward)\n",
        "\n",
        "        avg_score = np.mean(scores_deque)\n",
        "        avg_scores_array.append(avg_score)\n",
        "        \n",
        "        s = (int)(time.time() - time_start)        \n",
        "        print('Ep. {}, Ep.Timesteps {}, Score: {:.2f}, Avg.Score: {:.2f}, Run.Score {:.2f}, \\\n",
        "Time: {:02}:{:02}:{:02} '\\\n",
        "            .format(i_episode, timestep, \\\n",
        "                    total_reward, avg_score, running_score, s//3600, s%3600//60, s%60))  \n",
        "       \n",
        "        \n",
        "        # Save episode is equal to \"save_every\" timesteps\n",
        "        if i_episode+1 % save_every == 0:\n",
        "\n",
        "            suf = str(i_episode)\n",
        "            save(agent, '', 'model_weights', suf)\n",
        "            \n",
        "        if np.mean(scores_deque) > reward_threshold:\n",
        "            print(\"Solved environment! Running score is {:.2f}, Avg.Score: {:.2f} !\" \\\n",
        "                  .format(running_score, avg_score))\n",
        "            break\n",
        "            \n",
        "    return scores_array, avg_scores_array    \n",
        "            \n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:27:38.834591Z",
          "iopub.execute_input": "2022-01-05T20:27:38.83499Z",
          "iopub.status.idle": "2022-01-05T20:27:38.85386Z",
          "shell.execute_reply.started": "2022-01-05T20:27:38.834951Z",
          "shell.execute_reply": "2022-01-05T20:27:38.853052Z"
        },
        "trusted": true,
        "id": "mZxENj-6yWUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Agent"
      ],
      "metadata": {
        "id": "VdlbLDL8yWUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init the agent & the env\n",
        "agent = Agent(device)\n",
        "env_wrap = Wrapper(env)\n",
        "\n",
        "#number of episodes\n",
        "NUM_EPISODES = 1000\n",
        "\n",
        "#training the agent\n",
        "scores, avg_scores  = ppo_train(NUM_EPISODES)\n",
        "\n",
        "# Save latest model. We'll use it for testing later\n",
        "save(agent, '.', 'model_weights', 'latest')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:28:06.987454Z",
          "iopub.execute_input": "2022-01-05T20:28:06.987838Z",
          "iopub.status.idle": "2022-01-05T20:29:43.996195Z",
          "shell.execute_reply.started": "2022-01-05T20:28:06.987806Z",
          "shell.execute_reply": "2022-01-05T20:29:43.995217Z"
        },
        "trusted": true,
        "id": "eCL1jRjKyWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print the score figure\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print('length of scores: ', len(scores), ', len of avg_scores: ', len(avg_scores))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(1, len(scores)+1), scores, label=\"Score\")\n",
        "plt.plot(np.arange(1, len(avg_scores)+1), avg_scores, label=\"Avg on 100 episodes\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episodes #')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:29:58.16572Z",
          "iopub.execute_input": "2022-01-05T20:29:58.166406Z",
          "iopub.status.idle": "2022-01-05T20:29:58.362301Z",
          "shell.execute_reply.started": "2022-01-05T20:29:58.166368Z",
          "shell.execute_reply": "2022-01-05T20:29:58.361416Z"
        },
        "trusted": true,
        "id": "IeVHBH_ayWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to load the model chekpoints\n",
        "def load(agent, directory, filename):\n",
        "    agent.net.load_state_dict(torch.load(os.path.join(directory,filename)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:30:10.413648Z",
          "iopub.execute_input": "2022-01-05T20:30:10.414342Z",
          "iopub.status.idle": "2022-01-05T20:30:10.421091Z",
          "shell.execute_reply.started": "2022-01-05T20:30:10.414288Z",
          "shell.execute_reply": "2022-01-05T20:30:10.42012Z"
        },
        "trusted": true,
        "id": "aVjWitJhyWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to run a pretrained agent \n",
        "def play(env, agent, n_episodes):\n",
        "    state = env_wrap.reset()\n",
        "    \n",
        "    scores_deque = deque(maxlen=n_episodes)\n",
        "    scores = []\n",
        "    \n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "        state = env_wrap.reset()        \n",
        "        score = 0\n",
        "        \n",
        "        time_start = time.time()\n",
        "        \n",
        "        while True:\n",
        "            action, a_logp = agent.select_action(state)\n",
        "            env.render()\n",
        "            next_state, reward, done, die = env_wrap.step( \\\n",
        "                action * np.array([2., 1., 1.]) + np.array([-1., 0., 0.]))\n",
        "\n",
        "            state = next_state\n",
        "            score += reward\n",
        "            \n",
        "            if done or die:\n",
        "                break \n",
        "\n",
        "        s = (int)(time.time() - time_start)\n",
        "        \n",
        "        scores_deque.append(score)\n",
        "        scores.append(score)\n",
        "\n",
        "        print('Episode {}\\tAverage Score: {:.2f},\\tScore: {:.2f} \\tTime: {:02}:{:02}:{:02}'\\\n",
        "                  .format(i_episode, np.mean(scores_deque), score, s//3600, s%3600//60, s%60))\n",
        "    return np.mean(scores_deque)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:30:15.566105Z",
          "iopub.execute_input": "2022-01-05T20:30:15.56647Z",
          "iopub.status.idle": "2022-01-05T20:30:15.579032Z",
          "shell.execute_reply.started": "2022-01-05T20:30:15.566439Z",
          "shell.execute_reply": "2022-01-05T20:30:15.577766Z"
        },
        "trusted": true,
        "id": "oJAiZkPYyWUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Render training results"
      ],
      "metadata": {
        "id": "FRsKSS7IyWUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "env_test = Monitor(gym.make(\"CarRacing-v0\"), './video', force=True)\n",
        "env_test.reset()\n",
        "env_wrap = Wrapper(env_test)\n",
        "load(agent, '', 'model_weights_latest.pth')\n",
        "play(env_test, agent, n_episodes=1)\n",
        "while True:\n",
        "    env_test.render()\n",
        "    action = env_test.action_space.sample() \n",
        "    observation, reward, done, info = env_test.step(action)         \n",
        "    if done: \n",
        "      break;\n",
        "env_test.close()\n",
        "show_video()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-05T20:35:47.585271Z",
          "iopub.execute_input": "2022-01-05T20:35:47.585991Z",
          "iopub.status.idle": "2022-01-05T20:37:17.24273Z",
          "shell.execute_reply.started": "2022-01-05T20:35:47.585941Z",
          "shell.execute_reply": "2022-01-05T20:37:17.241693Z"
        },
        "trusted": true,
        "id": "CH547pw5yWUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.close()"
      ],
      "metadata": {
        "id": "vXk7TJIZyWUG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}